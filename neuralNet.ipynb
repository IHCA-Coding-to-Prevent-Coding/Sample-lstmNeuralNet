{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from statistics import mean, mode\n",
    "import torch\n",
    "from torch import nn\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "#from sklearn.metrics import roc_curve as roc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://towardsdatascience.com/lstms-in-pytorch-528b0440244\n",
    "# https://github.com/IHCA-Coding-to-Prevent-Coding/ML-SampleNeuralNet/blob/main/sampleneuralnet.py\n",
    "# data from https://archive.ics.uci.edu/ml/datasets/Power+consumption+of+Tetouan+city#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['DateTime', 'Temperature', 'Humidity', 'Wind Speed',\n",
       "       'general diffuse flows', 'diffuse flows', 'Zone 1 Power Consumption',\n",
       "       'Zone 2  Power Consumption', 'Zone 3  Power Consumption'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('Tetuan City power consumption.csv')\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "# changes data length so you don't run on 50,000 values every time\n",
    "data = data.iloc[:5000, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "xValues = data.iloc[:, [1, 2, 3, 4, 5]]\n",
    "yValues = data.iloc[:, [6]]\n",
    "assert len(xValues) == len(yValues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alternate data splitting that isn't week by week\n",
    "\n",
    "training, testing, trainTruth, testTruth = train_test_split(xValues, yValues)\n",
    "assert len(training)==len(trainTruth)\n",
    "assert len(testing)==len(testTruth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainTruth = torch.tensor(trainTruth.values)\n",
    "training = torch.tensor(training.values)\n",
    "\n",
    "testTruth = torch.tensor(testTruth.values)\n",
    "testing = torch.tensor(testing.values)\n",
    "\n",
    "training = training.float()\n",
    "testing = testing.float()\n",
    "trainTruth = trainTruth.float()\n",
    "testTruth = testTruth.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\naverage = mean(x.item() for x in testTruth)\\n\\nbinaryTestTruth = torch.tensor([float(x>average) for x in testTruth])\\n\\nbinaryTrainTruth = torch.tensor([float(x>average) for x in trainTruth])\\n'"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# binary values, if power usage is above average\n",
    "# getting if power usage is above average\n",
    "\n",
    "'''\n",
    "average = mean(x.item() for x in testTruth)\n",
    "\n",
    "binaryTestTruth = torch.tensor([float(x>average) for x in testTruth])\n",
    "\n",
    "binaryTrainTruth = torch.tensor([float(x>average) for x in trainTruth])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "average = mean(x.item() for x in trainTruth)\n",
    "\n",
    "binaryTestTruth = torch.tensor([float(x>average) for x in testTruth])\n",
    "\n",
    "binaryTrainTruth = torch.tensor([float(x>average) for x in trainTruth])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\natha\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([3750])) that is different to the input size (torch.Size([3750, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    }
   ],
   "source": [
    "#testing = torch.randn(batchSize, seqLength, inputSize)\n",
    "\n",
    "inputSize=5 # variables input\n",
    "hiddenSizeOne=32 # nodes of hidden layer\n",
    "hiddenSizeTwo=32 # nodes of hidden layer\n",
    "outSize=1 # power consumptoion in zone 1\n",
    "batchSize= 144*7 # how many data points are in batch\n",
    "lr = 0.05\n",
    "seqLength=144 # num of time values per input\n",
    "epochSize = 10\n",
    "\n",
    "class extractTensor(nn.Module):\n",
    "    def forward(self, x):\n",
    "        tensor, hs = x\n",
    "        return tensor.reshape(-1, hiddenSizeOne) \n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.LSTM(inputSize, hiddenSizeOne),\n",
    "    extractTensor(),\n",
    "    #nn.Sigmoid(),\n",
    "    nn.Linear(hiddenSizeOne, hiddenSizeTwo),\n",
    "    #nn.Sigmoid(),\n",
    "    nn.Linear(hiddenSizeTwo, outSize)\n",
    "    # nn.Sigmoid() \n",
    "    #nn.Linear(linearSize, outSize)\n",
    ")\n",
    "\n",
    "def lossFunc(data=training, comparison=trainTruth, model=model):\n",
    "    prediction = model(data)\n",
    "\n",
    "    MSEloss = torch.nn.MSELoss()\n",
    "    output = MSEloss(prediction, comparison)\n",
    "    \n",
    "    return output, prediction\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "\n",
    "# model training starts here\n",
    "lossList = []\n",
    "for i in range(epochSize):\n",
    "    loss, output = lossFunc(comparison = binaryTrainTruth)\n",
    "    lossList.append(loss.item())\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "plt.plot(lossList)\n",
    "training_loss = loss.item();\n",
    "print(f'total change in loss: {lossList[0]-lossList[-1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss:    0.25041723251342773\n",
      "testing loss:     0.25081372261047363\n",
      "testing-training: 0.00039649009704589844\n",
      "testing/training: 0.9984191849914781\n",
      "% error           0.0015808150085219522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\natha\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([1250])) that is different to the input size (torch.Size([1250, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    testing_loss, prediction = lossFunc(testing, binaryTestTruth);\n",
    "    testing_loss = testing_loss.item()\n",
    "   \n",
    "    print(f\"training loss:    {training_loss}\");\n",
    "    print(f\"testing loss:     {testing_loss}\");\n",
    "    print(f\"testing-training: {abs(testing_loss-training_loss)}\");\n",
    "    print(f\"testing/training: {training_loss/testing_loss}\");\n",
    "    print(f\"% error           {abs(testing_loss-training_loss)/testing_loss}\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicting same thing 0.08%\n"
     ]
    }
   ],
   "source": [
    "common = mode([float(x) for x in output])\n",
    "\n",
    "count=0\n",
    "for x in output:\n",
    "    if x == common:\n",
    "        count+=1\n",
    "\n",
    "print(f'predicting same thing {count/len(prediction)*100}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rounding percentage chances to 1 or 0 floats\n",
    "binaryPred = []\n",
    "for pred in prediction:\n",
    "    if pred.item() >= 0.5:\n",
    "        binaryPred.append(1.0)\n",
    "    else:\n",
    "        binaryPred.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://towardsdatascience.com/how-to-calculate-roc-auc-score-for-regression-models-c0be4fdf76bb\n",
    "\n",
    "# continuous auroc calculator from the internet\n",
    "def regression_roc_auc_score(y_true, y_pred, num_rounds = 10000):\n",
    "  \"\"\"\n",
    "  Computes Regression-ROC-AUC-score.\n",
    "  \n",
    "  Parameters:\n",
    "  ----------\n",
    "  y_true: array-like of shape (n_samples,). Binary or continuous target variable.\n",
    "  y_pred: array-like of shape (n_samples,). Target scores.\n",
    "  num_rounds: int or string. If integer, number of random pairs of observations. \n",
    "              If string, 'exact', all possible pairs of observations will be evaluated.\n",
    "  \n",
    "  Returns:\n",
    "  -------\n",
    "  rroc: float. Regression-ROC-AUC-score.\n",
    "  \"\"\"\n",
    "\n",
    "    \n",
    "  y_true = np.array(y_true)\n",
    "  y_pred = np.array(y_pred)\n",
    "\n",
    "  num_pairs = 0\n",
    "  num_same_sign = 0\n",
    "  \n",
    "  for i, j in _yield_pairs(y_true, num_rounds):\n",
    "    diff_true = y_true[i] - y_true[j]\n",
    "    diff_score = y_pred[i] - y_pred[j]\n",
    "    if diff_true * diff_score > 0:\n",
    "      num_same_sign += 1\n",
    "    elif diff_score == 0:\n",
    "      num_same_sign += .5\n",
    "    num_pairs += 1\n",
    "      \n",
    "  return num_same_sign / num_pairs\n",
    "\n",
    "\n",
    "def _yield_pairs(y_true, num_rounds):\n",
    "  \"\"\"\n",
    "  Returns pairs of valid indices. Indices must belong to observations having different values.\n",
    "  \n",
    "  Parameters:\n",
    "  ----------\n",
    "  y_true: array-like of shape (n_samples,). Binary or continuous target variable.\n",
    "  num_rounds: int or string. If integer, number of random pairs of observations to return. \n",
    "              If string, 'exact', all possible pairs of observations will be returned.\n",
    "  \n",
    "  Yields:\n",
    "  -------\n",
    "  i, j: tuple of int of shape (2,). Indices referred to a pair of samples.\n",
    "  \n",
    "  \"\"\"\n",
    "  \n",
    "  if num_rounds == 'exact':\n",
    "    for i in range(len(y_true)):\n",
    "      for j in np.where((y_true != y_true[i]) & (np.arange(len(y_true)) > i))[0]:\n",
    "        yield i, j     \n",
    "  else:\n",
    "    for r in range(num_rounds):\n",
    "      i = np.random.choice(range(len(y_true)))\n",
    "      j = np.random.choice(np.where(y_true != y_true[i])[0])\n",
    "      yield i, j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUROC value: 0.4585\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "roc_auc_score is defined as the area under the ROC curve, which is the curve having False Positive Rate on the x-axis \n",
    "and True Positive Rate on the y-axis at all classification thresholds. \n",
    "But it’s impossible to calculate FPR and TPR for regression methods, so we cannot take this road.\n",
    "\n",
    "Luckily for us, there is an alternative definition. In fact, according to Wikipedia, \n",
    "roc_auc_score coincides with “the probability that a classifier will rank a randomly \n",
    "chosen positive instance higher than a randomly chosen negative one”.\n",
    "'''\n",
    "# is this what we want??\n",
    "\n",
    "print(f\"AUROC value: {regression_roc_auc_score(binaryTestTruth, binaryPred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 47.44\n"
     ]
    }
   ],
   "source": [
    "# accuracy for binary prediction\n",
    "\n",
    "correct=0\n",
    "for i in range(len(binaryPred)):\n",
    "    if binaryPred[i] == binaryTestTruth[i]:\n",
    "        correct+=1\n",
    "print(f'accuracy: {(correct/ len(prediction))*100}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO need cross validation, individual runs vary by +-10% accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "89627e806f793b932dfe80791ab48950fda4fb8e20d46d5d1c8fbf2fdce875b2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
